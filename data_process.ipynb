{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path='data/processed'\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Multilingual Amazon Reviews Corpus"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the implementation easy we are using huggingface dataset for the dataset. One can also download the dataset from original site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "amaz_t={\n",
    "    'de':'Rezension: {s} Bewertung:',\n",
    "    'ja':'レビュー: {s} 評価:',\n",
    "    'es':'Revisar: {s} Clasificación:',\n",
    "    'fr':'Examen: {s} Évaluation:',\n",
    "    'zh':'审查: {s} 评分:',\n",
    "    'en':'Review: {s} Rating:'\n",
    "    \n",
    "}\n",
    "\n",
    "amaz_bi_v={\n",
    "    'en':{\n",
    "        'negative':'bad',\n",
    "        'positive':'good'\n",
    "    },\n",
    "    'fr':{\n",
    "        'negative':'mal',\n",
    "        'positive':'bien'\n",
    "    },\n",
    "    'es':{\n",
    "        'negative':'malo',\n",
    "        'positive':'bueno'\n",
    "    },\n",
    "    'ja':{\n",
    "        'negative':'悪い',\n",
    "        'positive':'良い'\n",
    "    },\n",
    "    'zh':{\n",
    "        'negative':'坏的',\n",
    "        'positive':'好的'\n",
    "    },\n",
    "    'de':{\n",
    "        'negative':'Schlecht',\n",
    "        'positive':'gut'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset amazon_reviews_multi (/home/eshaant/.cache/huggingface/datasets/amazon_reviews_multi/all_languages/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b723c2d6bd1645198113ef0a3d5a9e81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train set\n",
    "train_marc=load_dataset('amazon_reviews_multi','all_languages')['train']\n",
    "\n",
    "language=[]\n",
    "input=[]\n",
    "output=[]\n",
    "id=[]\n",
    "\n",
    "for d in train_marc:\n",
    "\n",
    "    l=d['language']\n",
    "\n",
    "    if d['stars']==3:\n",
    "        continue\n",
    "    elif d['stars'] in [1,2]:\n",
    "        output.append(amaz_bi_v[l]['negative'])\n",
    "    elif d['stars'] in [4,5]:\n",
    "        output.append(amaz_bi_v[l]['positive'])\n",
    "    \n",
    "    input.append(amaz_t[l].format(s=d['review_body']))\n",
    "    id.append(d['review_id'])\n",
    "    language.append(l)\n",
    "\n",
    "marc_df={\n",
    "    'id':id,\n",
    "    'input':input,\n",
    "    'output':output,\n",
    "    'language':language\n",
    "}\n",
    "marc_df=pd.DataFrame(marc_df)\n",
    "marc_df.to_csv('data/processed/amaz_bi_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset amazon_reviews_multi (/home/eshaant/.cache/huggingface/datasets/amazon_reviews_multi/all_languages/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03d6e6e0da474124a4dc41740f166df9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test set\n",
    "test_marc=load_dataset('amazon_reviews_multi','all_languages')['test']\n",
    "\n",
    "language=[]\n",
    "input=[]\n",
    "output=[]\n",
    "id=[]\n",
    "\n",
    "for d in test_marc:\n",
    "\n",
    "    l=d['language']\n",
    "\n",
    "    if d['stars']==3:\n",
    "        continue\n",
    "    elif d['stars'] in [1,2]:\n",
    "        output.append(amaz_bi_v[l]['negative'])\n",
    "    elif d['stars'] in [4,5]:\n",
    "        output.append(amaz_bi_v[l]['positive'])\n",
    "    \n",
    "    input.append(amaz_t[l].format(s=d['review_body']))\n",
    "    id.append(d['review_id'])\n",
    "    language.append(l)\n",
    "\n",
    "marc_df={\n",
    "    'id':id,\n",
    "    'input':input,\n",
    "    'output':output,\n",
    "    'language':language\n",
    "}\n",
    "marc_df=pd.DataFrame(marc_df)\n",
    "marc_df.to_csv('data/processed/amaz_bi_test.csv')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hateval 2019"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INSTRUCTION FOR HATE EVAL\n",
    "\n",
    "We have used relabeled version of Hateeval that can be found in [this link](https://github.com/sentropytechnologies/hateval2019-relabeled)\n",
    "please download the dataset from the said link and save the csvs in a folder data/raw/hateval2019\n",
    "\n",
    "The git goesnt contain text(tweets), so to extract that download the original hateval by downloading from [this link](http://hatespeech.di.unito.it/hateval.html) and save the csvs in a folder data/raw/hateval2019/original\n",
    "\n",
    "We have included the validation set of hateval in our traning set to increase the data retrival space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "hateval_t={\n",
    "    'es':'correo: {s} Es odioso?',\n",
    "    'en':'Post: {s} Is hatefull:'\n",
    "    \n",
    "}\n",
    "\n",
    "hateval_v={\n",
    "    'en':{\n",
    "        1:'yes',\n",
    "        0:'no'\n",
    "    },\n",
    "    'es':{\n",
    "        1:'sí',\n",
    "        0:'no'\n",
    "    }\n",
    "}\n",
    "\n",
    "l=['es','en']\n",
    "\n",
    "def get_input(i,l):\n",
    "    return hateval_t[l].format(s=i)\n",
    "\n",
    "def get_output(o,l):\n",
    "    return hateval_v[l][o]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set + dev set\n",
    "re_label_train_es=pd.read_csv('data/raw/hateval2019/hateval2019-relabeled-main/data/hateval2019_es_train.csv')\n",
    "old_label_train_es=pd.read_csv('data/raw/hateval2019/original/hateval2019_es_train.csv').drop(columns=['HS','TR','AG'])\n",
    "df_train_es=re_label_train_es.merge(old_label_train_es,on='id')\n",
    "df_train_es['language']=['es']*len(df_train_es)\n",
    "df_train_es['input']=df_train_es.apply(lambda x: get_input(x.text,x.language), axis=1)\n",
    "df_train_es['output']=df_train_es.apply(lambda x: get_output(x.HS,x.language), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "re_label_train_en=pd.read_csv('data/raw/hateval2019/hateval2019-relabeled-main/data/hateval2019_en_train.csv')\n",
    "old_label_train_en=pd.read_csv('data/raw/hateval2019/original/hateval2019_en_train.csv').drop(columns=['HS','TR','AG'])\n",
    "df_train_en=re_label_train_en.merge(old_label_train_en,on='id')\n",
    "df_train_en['language']=['en']*len(df_train_en)\n",
    "df_train_en['input']=df_train_en.apply(lambda x: get_input(x.text,x.language), axis=1)\n",
    "df_train_en['output']=df_train_en.apply(lambda x: get_output(x.HS,x.language), axis=1)\n",
    "\n",
    "re_label_dev_es=pd.read_csv('data/raw/hateval2019/hateval2019-relabeled-main/data/hateval2019_es_dev.csv')\n",
    "old_label_dev_es=pd.read_csv('data/raw/hateval2019/original/hateval2019_es_dev.csv').drop(columns=['HS','TR','AG'])\n",
    "df_dev_es=re_label_dev_es.merge(old_label_dev_es,on='id')\n",
    "df_dev_es['language']=['es']*len(df_dev_es)\n",
    "df_dev_es['input']=df_dev_es.apply(lambda x: get_input(x.text,x.language), axis=1)\n",
    "df_dev_es['output']=df_dev_es.apply(lambda x: get_output(x.HS,x.language), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "re_label_dev_en=pd.read_csv('data/raw/hateval2019/hateval2019-relabeled-main/data/hateval2019_en_dev.csv')\n",
    "old_label_dev_en=pd.read_csv('data/raw/hateval2019/original/hateval2019_en_dev.csv').drop(columns=['HS','TR','AG'])\n",
    "df_dev_en=re_label_dev_en.merge(old_label_dev_en,on='id')\n",
    "df_dev_en['language']=['en']*len(df_dev_en)\n",
    "df_dev_en['input']=df_dev_en.apply(lambda x: get_input(x.text,x.language), axis=1)\n",
    "df_dev_en['output']=df_dev_en.apply(lambda x: get_output(x.HS,x.language), axis=1)\n",
    "\n",
    "df_train=pd.concat([df_dev_es,df_train_es,df_dev_en,df_train_en])\n",
    "\n",
    "df_train.to_csv('data/processed/hateval_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set\n",
    "re_label_test_es=pd.read_csv('data/raw/hateval2019/hateval2019-relabeled-main/data/hateval2019_es_test.csv')\n",
    "old_label_test_es=pd.read_csv('data/raw/hateval2019/original/hateval2019_es_test.csv').drop(columns=['HS','TR','AG'])\n",
    "df_test_es=re_label_test_es.merge(old_label_test_es,on='id')\n",
    "df_test_es['language']=['es']*len(df_test_es)\n",
    "df_test_es['input']=df_test_es.apply(lambda x: get_input(x.text,x.language), axis=1)\n",
    "df_test_es['output']=df_test_es.apply(lambda x: get_output(x.HS,x.language), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "re_label_test_en=pd.read_csv('data/raw/hateval2019/hateval2019-relabeled-main/data/hateval2019_en_test.csv')\n",
    "old_label_test_en=pd.read_csv('data/raw/hateval2019/original/hateval2019_en_test.csv').drop(columns=['HS','TR','AG'])\n",
    "df_test_en=re_label_test_en.merge(old_label_test_en,on='id')\n",
    "df_test_en['language']=['en']*len(df_test_en)\n",
    "df_test_en['input']=df_test_en.apply(lambda x: get_input(x.text,x.language), axis=1)\n",
    "df_test_en['output']=df_test_en.apply(lambda x: get_output(x.HS,x.language), axis=1)\n",
    "df_test=pd.concat([df_test_es,df_test_en])\n",
    "\n",
    "df_test.to_csv('data/processed/hateval_test.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessto cls can be found through [link](https://webis.de/data/webis-cls-10.html). Savethe dataset in the folder data/raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "langs=['en','de','fr','jp']\n",
    "topics=['books','dvd','music']\n",
    "df_train=pd.DataFrame()\n",
    "df_test=pd.DataFrame()\n",
    "\n",
    "for l in langs:\n",
    "    for t in topics:\n",
    "        df1=pd.read_xml(f'data/raw/cls-acl10-unprocessed/{l}/{t}/train.review')\n",
    "        df2=pd.read_xml(f'data/raw/cls-acl10-unprocessed/{l}/{t}/test.review')\n",
    "        \n",
    "        df1['topic_number']=[t]*len(df1)\n",
    "        df2['topic_number']=[t]*len(df2)\n",
    "\n",
    "        df1['language']=[l]*len(df1)\n",
    "        df2['language']=[l]*len(df2)\n",
    "\n",
    "        \n",
    "\n",
    "        df_train=pd.concat([df_train,df1])\n",
    "        df_test=pd.concat([df_test,df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_v={\n",
    "    'en':{\n",
    "        'negative':'bad',\n",
    "        'positive':'good'\n",
    "    },\n",
    "    'fr':{\n",
    "        'negative':'mal',\n",
    "        'positive':'bien'\n",
    "    },\n",
    "    'jp':{\n",
    "        'negative':'悪い',\n",
    "        'positive':'良い'\n",
    "    },\n",
    "    'de':{\n",
    "        'negative':'Schlecht',\n",
    "        'positive':'gut'\n",
    "    }\n",
    "}\n",
    "\n",
    "def verbiliser(l,i):\n",
    "    if i in [1.0,2.0]:\n",
    "        return cls_v[l]['negative']\n",
    "    elif i in [4.0,5.0]:\n",
    "        return cls_v[l]['positive']\n",
    "    else:\n",
    "        return\n",
    "df_train['output']=df_train.apply(lambda x: verbiliser(x['language'],x['rating']),axis=1)\n",
    "df_test['output']=df_test.apply(lambda x: verbiliser(x['language'],x['rating']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_temp={\n",
    "    'fr':{\n",
    "        'Review':'Examen: ',\n",
    "        'Rating':' Évaluation:'\n",
    "\n",
    "    },\n",
    "    'en':{\n",
    "        'Review':'Review: ',\n",
    "        'Rating':' Rating:'\n",
    "\n",
    "    },\n",
    "    'jp':{\n",
    "        'Review':'レビュー: ',\n",
    "        'Rating':' 評価:'\n",
    "    },\n",
    "    'de':{\n",
    "        'Review':'Rezension: ',\n",
    "        'Rating':'Bewertung:'\n",
    "\n",
    "    }\n",
    "}\n",
    "\n",
    "def temp(l,s):\n",
    "    return cls_temp[l]['Review']+str(s)+cls_temp[l]['Rating']\n",
    "  \n",
    "df_train['input']=df_train.apply(lambda x: temp(x['language'],x['text']),axis=1)\n",
    "df_train.to_csv('cls_train.csv')\n",
    "\n",
    "df_test['input']=df_test.apply(lambda x: temp(x['language'],x['text']),axis=1)\n",
    "df_test.to_csv('cls_test.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
